"""
==============================================================================
PHáº¦N 4: INFERENCE & BLEU EVALUATION
==============================================================================
TuÃ¢n thá»§ yÃªu cáº§u Ä‘á»“ Ã¡n:
- HÃ m translate(sentence: str) -> str
- ÄÃ¡nh giÃ¡ BLEU báº±ng nltk.translate.bleu_score
- Demo dá»‹ch 5 cÃ¢u tá»« táº­p Test
==============================================================================
"""

import torch
import random
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from tqdm import tqdm

# ==============================================================================
# 1. HÃ€M TRANSLATE (ÄÃšNG SIGNATURE YÃŠU Cáº¦U)
# ==============================================================================
def translate(sentence: str) -> str:
    """
    Dá»‹ch má»™t cÃ¢u tiáº¿ng Anh sang tiáº¿ng PhÃ¡p.
    
    Args:
        sentence: CÃ¢u tiáº¿ng Anh cáº§n dá»‹ch (string)
        
    Returns:
        CÃ¢u tiáº¿ng PhÃ¡p Ä‘Ã£ dá»‹ch (string)
        
    LÆ°u Ã½: HÃ m nÃ y sá»­ dá»¥ng cÃ¡c biáº¿n global:
        - model, device, vocab_en, vocab_fr, tokenizer_en
        - SOS_IDX, EOS_IDX
    """
    MAX_LEN = 50
    
    model.eval()
    
    # ===== 1. TOKENIZE =====
    # DÃ¹ng spacy tokenizer
    tokens = tokenizer_en(sentence.lower())
    
    # ThÃªm <sos> vÃ  <eos>
    tokens = ['<sos>'] + tokens + ['<eos>']
    
    # ===== 2. NUMERICALIZE =====
    # Chuyá»ƒn token thÃ nh index
    src_indexes = [vocab_en[token] for token in tokens]
    
    # ===== 3. TENSORIZE =====
    # Shape: [seq_len, 1] (batch_size = 1)
    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)
    
    # ===== 4. TÃNH SRC_LEN =====
    # âš ï¸ QUAN TRá»ŒNG: src_len PHáº¢I náº±m trÃªn CPU
    src_len = torch.tensor([len(src_indexes)], dtype=torch.long)  # CPU
    
    # ===== 5. ENCODER FORWARD =====
    with torch.no_grad():
        hidden, cell = model.encoder(src_tensor, src_len)
    
    # ===== 6. GREEDY DECODING =====
    # Báº¯t Ä‘áº§u vá»›i <sos>
    trg_indexes = [SOS_IDX]
    
    for _ in range(MAX_LEN):
        # Láº¥y token cuá»‘i lÃ m input
        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)
        
        with torch.no_grad():
            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)
        
        # Greedy: chá»n tá»« cÃ³ xÃ¡c suáº¥t cao nháº¥t (argmax)
        pred_token = output.argmax(1).item()
        
        trg_indexes.append(pred_token)
        
        # Dá»«ng khi gáº·p <eos>
        if pred_token == EOS_IDX:
            break
    
    # ===== 7. CONVERT TO WORDS =====
    # Chuyá»ƒn index thÃ nh tá»« vá»±ng
    trg_tokens = [vocab_fr.get_itos()[i] for i in trg_indexes]
    
    # Bá» <sos> Ä‘áº§u vÃ  <eos> cuá»‘i (náº¿u cÃ³)
    if trg_tokens[0] == '<sos>':
        trg_tokens = trg_tokens[1:]
    if '<eos>' in trg_tokens:
        trg_tokens = trg_tokens[:trg_tokens.index('<eos>')]
    
    # Tráº£ vá» cÃ¢u dá»‹ch dáº¡ng string
    return ' '.join(trg_tokens)


# ==============================================================================
# 2. HÃ€M TÃNH BLEU SCORE (DÃ¹ng NLTK)
# ==============================================================================
def calculate_bleu_score(test_src, test_trg, num_samples=None):
    """
    TÃ­nh Ä‘iá»ƒm BLEU trung bÃ¬nh trÃªn táº­p Test.
    
    Args:
        test_src: List cÃ¢u nguá»“n (tiáº¿ng Anh)
        test_trg: List cÃ¢u Ä‘Ã­ch (tiáº¿ng PhÃ¡p)
        num_samples: Sá»‘ máº«u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ (None = toÃ n bá»™)
        
    Returns:
        bleu_avg: Äiá»ƒm BLEU trung bÃ¬nh (0-1)
    """
    # Smoothing function Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p n-gram = 0
    smooth = SmoothingFunction().method1
    
    total_bleu = 0
    count = 0
    
    # Giá»›i háº¡n sá»‘ máº«u náº¿u cáº§n
    if num_samples:
        indices = random.sample(range(len(test_src)), min(num_samples, len(test_src)))
    else:
        indices = range(len(test_src))
    
    print("Äang tÃ­nh BLEU Score...")
    
    for idx in tqdm(indices, desc="Calculating BLEU"):
        src_sentence = test_src[idx]
        trg_sentence = test_trg[idx]
        
        # Dá»‹ch cÃ¢u
        pred_sentence = translate(src_sentence)
        
        # Tokenize prediction vÃ  reference
        pred_tokens = pred_sentence.split()
        ref_tokens = tokenizer_fr(trg_sentence.lower())
        
        # NLTK sentence_bleu yÃªu cáº§u:
        # - references: list of list of tokens (cÃ³ thá»ƒ nhiá»u reference)
        # - hypothesis: list of tokens
        reference = [ref_tokens]  # Wrap trong list
        hypothesis = pred_tokens
        
        # TÃ­nh BLEU cho cÃ¢u nÃ y
        try:
            bleu = sentence_bleu(reference, hypothesis, smoothing_function=smooth)
            total_bleu += bleu
            count += 1
        except:
            # Bá» qua náº¿u cÃ³ lá»—i
            continue
    
    bleu_avg = total_bleu / count if count > 0 else 0
    return bleu_avg


# ==============================================================================
# 3. HÃ€M DEMO Dá»ŠCH
# ==============================================================================
def demo_translation(test_src, test_trg, num_examples=5):
    """
    Demo dá»‹ch má»™t sá»‘ cÃ¢u ngáº«u nhiÃªn tá»« táº­p Test.
    
    Args:
        test_src: List cÃ¢u nguá»“n
        test_trg: List cÃ¢u Ä‘Ã­ch
        num_examples: Sá»‘ cÃ¢u vÃ­ dá»¥
    """
    print("\n" + "=" * 70)
    print(" DEMO Dá»ŠCH MáºªU")
    print("=" * 70)
    
    # Chá»n ngáº«u nhiÃªn
    indices = random.sample(range(len(test_src)), num_examples)
    
    for i, idx in enumerate(indices, 1):
        src = test_src[idx]
        trg = test_trg[idx]
        pred = translate(src)
        
        print(f"\n--- VÃ­ dá»¥ {i} ---")
        print(f"ğŸ“¥ Source (EN):     {src}")
        print(f"ğŸ“Œ Reference (FR):  {trg}")
        print(f"ğŸ¤– Predicted (FR):  {pred}")
    
    print("\n" + "=" * 70)


# ==============================================================================
# 4. MAIN EXECUTION
# ==============================================================================

print("=" * 70)
print(" PHáº¦N 4: INFERENCE & BLEU EVALUATION")
print("=" * 70)

# ----- LOAD BEST MODEL -----
model.load_state_dict(torch.load('best_model.pth', map_location=device))
model.eval()
print("âœ… ÄÃ£ load model tá»« 'best_model.pth'\n")

# ----- DEMO: Dá»ŠCH 5 CÃ‚U NGáºªU NHIÃŠN Tá»ª Táº¬P TEST -----
demo_translation(test_en, test_fr, num_examples=5)

# ----- TÃNH BLEU SCORE -----
print("\n" + "=" * 70)
print(" ÄÃNH GIÃ BLEU SCORE TRÃŠN Táº¬P TEST")
print("=" * 70)

# TÃ­nh BLEU trÃªn toÃ n bá»™ táº­p test (hoáº·c giá»›i háº¡n Ä‘á»ƒ cháº¡y nhanh)
bleu_score_avg = calculate_bleu_score(test_en, test_fr, num_samples=None)

print("\n" + "=" * 70)
print(f" ğŸ¯ BLEU SCORE TRUNG BÃŒNH: {bleu_score_avg * 100:.2f}")
print("=" * 70)

# ----- Báº¢NG ÄÃNH GIÃ BLEU -----
print("""
ğŸ“Š HÆ¯á»šNG DáºªN ÄÃNH GIÃ BLEU SCORE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BLEU Score      â”‚ ÄÃ¡nh giÃ¡                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ < 10%           â”‚ KÃ©m - Gáº§n nhÆ° vÃ´ nghÄ©a           â”‚
â”‚ 10% - 19%       â”‚ Yáº¿u - KhÃ³ hiá»ƒu                   â”‚
â”‚ 20% - 29%       â”‚ Trung bÃ¬nh - Hiá»ƒu Ã½ chÃ­nh        â”‚
â”‚ 30% - 40%       â”‚ KhÃ¡ - Cháº¥t lÆ°á»£ng cháº¥p nháº­n Ä‘Æ°á»£c  â”‚
â”‚ 40% - 50%       â”‚ Tá»‘t - Cháº¥t lÆ°á»£ng cao             â”‚
â”‚ > 50%           â”‚ Ráº¥t tá»‘t - Gáº§n vá»›i ngÆ°á»i dá»‹ch     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Œ LÆ°u Ã½: MÃ´ hÃ¬nh Seq2Seq cÆ¡ báº£n (khÃ´ng Attention) thÆ°á»ng Ä‘áº¡t 15-25%.
""")


# ==============================================================================
# 5. Dá»ŠCH THá»¬ CÃ‚U Tá»° NHáº¬P
# ==============================================================================
print("\n" + "=" * 70)
print(" Dá»ŠCH THá»¬ CÃ‚U TÃ™Y Ã")
print("=" * 70)

test_sentences = [
    "I love machine learning.",
    "The weather is beautiful today.",
    "A man is walking with his dog.",
]

for sentence in test_sentences:
    result = translate(sentence)
    print(f"EN: {sentence}")
    print(f"FR: {result}")
    print("-" * 50)


# ==============================================================================
# 6. CHáº¾ Äá»˜ TÆ¯Æ NG TÃC (Optional - Uncomment Ä‘á»ƒ sá»­ dá»¥ng)
# ==============================================================================
"""
def interactive_mode():
    print("\\n" + "=" * 70)
    print(" CHáº¾ Äá»˜ Dá»ŠCH TÆ¯Æ NG TÃC")
    print(" Nháº­p 'quit' Ä‘á»ƒ thoÃ¡t")
    print("=" * 70)
    
    while True:
        sentence = input("\\nğŸ“ Nháº­p cÃ¢u tiáº¿ng Anh: ").strip()
        
        if sentence.lower() == 'quit':
            print("ğŸ‘‹ Táº¡m biá»‡t!")
            break
        
        if not sentence:
            print("âš ï¸ Vui lÃ²ng nháº­p cÃ¢u!")
            continue
        
        result = translate(sentence)
        print(f"ğŸ‡«ğŸ‡· Káº¿t quáº£: {result}")

# Uncomment Ä‘á»ƒ cháº¡y:
# interactive_mode()
"""
