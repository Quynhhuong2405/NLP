{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## PHẦN 1: TẢI VÀ XỬ LÝ DỮ LIỆU"
      ],
      "metadata": {
        "id": "K5kKms5Xk6s3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGwW3in4hk-o",
        "outputId": "0281a429-1d7a-4f73-82b1-3d7db4c68d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.12/dist-packages (2.3.1)\n",
            "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Torch version: 2.3.1+cu121\n",
            "Torchtext version: 0.18.0+cpu\n",
            "total 5352\n",
            "drwxr-xr-x 2 root root    4096 Dec 11 18:30 .\n",
            "drwxr-xr-x 1 root root    4096 Dec 11 17:53 ..\n",
            "-rw-r--r-- 1 root root   62076 Dec 11 18:30 test.en\n",
            "-rw-r--r-- 1 root root   21077 Dec 11 18:30 test.en.gz\n",
            "-rw-r--r-- 1 root root   72261 Dec 11 18:30 test.fr\n",
            "-rw-r--r-- 1 root root   22310 Dec 11 18:30 test.fr.gz\n",
            "-rw-r--r-- 1 root root 1801238 Dec 11 18:30 train.en\n",
            "-rw-r--r-- 1 root root  568929 Dec 11 18:30 train.en.gz\n",
            "-rw-r--r-- 1 root root 2111303 Dec 11 18:30 train.fr\n",
            "-rw-r--r-- 1 root root  604242 Dec 11 18:30 train.fr.gz\n",
            "-rw-r--r-- 1 root root   63297 Dec 11 18:30 val.en\n",
            "-rw-r--r-- 1 root root   21650 Dec 11 18:30 val.en.gz\n",
            "-rw-r--r-- 1 root root   73924 Dec 11 18:30 val.fr\n",
            "-rw-r--r-- 1 root root   23001 Dec 11 18:30 val.fr.gz\n",
            "✅ Đã chuẩn bị xong dữ liệu và thư viện!\n"
          ]
        }
      ],
      "source": [
        "# 1. Cài đặt thư viện\n",
        "!pip install -U torch==2.3.1 torchtext==0.18.0 spacy portalocker\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import io\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "# Kiểm tra phiên bản\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Torchtext version: {torchtext.__version__}\")\n",
        "\n",
        "# Tải dataset Multi30K (en-fr)\n",
        "!mkdir -p data\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.en.gz -O data/train.en.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/train.fr.gz -O data/train.fr.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.en.gz -O data/val.en.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/val.fr.gz -O data/val.fr.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/test_2016_flickr.en.gz -O data/test.en.gz\n",
        "!wget -q https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/test_2016_flickr.fr.gz -O data/test.fr.gz\n",
        "\n",
        "# Giải nén\n",
        "!gunzip -kf data/*.gz\n",
        "!ls -la data/\n",
        "\n",
        "print(\"✅ Đã chuẩn bị xong dữ liệu và thư viện!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- BƯỚC PHỤ: KIỂM TRA DỮ LIỆU (DÙNG ĐỂ VIẾT BÁO CÁO) ---\n",
        "\n",
        "def read_data(en_file, fr_file):\n",
        "    with open(en_file, 'r', encoding='utf-8') as f:\n",
        "        en_sentences = [line.strip() for line in f.readlines() if line.strip()]\n",
        "    with open(fr_file, 'r', encoding='utf-8') as f:\n",
        "        fr_sentences = [line.strip() for line in f.readlines() if line.strip()]\n",
        "    return en_sentences, fr_sentences\n",
        "\n",
        "# Đọc dữ liệu train, val, test từ folder 'data/'\n",
        "train_en, train_fr = read_data('data/train.en', 'data/train.fr')\n",
        "val_en, val_fr = read_data('data/val.en', 'data/val.fr')\n",
        "test_en, test_fr = read_data('data/test.en', 'data/test.fr')\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(\"THỐNG KÊ DỮ LIỆU \")\n",
        "print(\"=\"*30)\n",
        "print(f\" Train: {len(train_en)} cặp câu \")\n",
        "print(f\" Validation: {len(val_en)} cặp câu \")\n",
        "print(f\" Test: {len(test_en)} cặp câu \")\n",
        "\n",
        "# Hiển thị ví dụ\n",
        "print(\"\\n---  Ví dụ 5 cặp câu đầu tiên ---\")\n",
        "for i in range(5):\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\" - EN: {train_en[i]}\")\n",
        "    print(f\" - FR: {train_fr[i]}\")\n",
        "    print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgtl2UdijV7e",
        "outputId": "c435739f-5680-40d8-9a1f-6af9380fecc9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "THỐNG KÊ DỮ LIỆU \n",
            "==============================\n",
            " Train: 29000 cặp câu \n",
            " Validation: 1014 cặp câu \n",
            " Test: 1000 cặp câu \n",
            "\n",
            "---  Ví dụ 5 cặp câu đầu tiên ---\n",
            "Example 1:\n",
            " - EN: Two young, White males are outside near many bushes.\n",
            " - FR: Deux jeunes hommes blancs sont dehors près de buissons.\n",
            "--------------------\n",
            "Example 2:\n",
            " - EN: Several men in hard hats are operating a giant pulley system.\n",
            " - FR: Plusieurs hommes en casque font fonctionner un système de poulies géant.\n",
            "--------------------\n",
            "Example 3:\n",
            " - EN: A little girl climbing into a wooden playhouse.\n",
            " - FR: Une petite fille grimpe dans une maisonnette en bois.\n",
            "--------------------\n",
            "Example 4:\n",
            " - EN: A man in a blue shirt is standing on a ladder cleaning a window.\n",
            " - FR: Un homme dans une chemise bleue se tient sur une échelle pour nettoyer une fenêtre.\n",
            "--------------------\n",
            "Example 5:\n",
            " - EN: Two men are at the stove preparing food.\n",
            " - FR: Deux hommes aux fourneaux préparent à manger.\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CẤU HÌNH TOKEN ĐẶC BIỆT (<unk>, <pad>, <sos>, <eos>) ---\n",
        "\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "SPECIAL_SYMBOLS = ['<unk>', '<pad>', '<sos>', '<eos>']\n",
        "\n",
        "# 1. HÀM: get_tokenizers()\n",
        "# Nhiệm vụ: Tải và trả về object tokenizer của spacy cho tiếng Anh và Pháp.\n",
        "\n",
        "def get_tokenizers():\n",
        "    try:\n",
        "        en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "        fr_tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\n",
        "        print(\" Đã tải thành công Tokenizer (Spacy).\")\n",
        "        return en_tokenizer, fr_tokenizer\n",
        "    except OSError:\n",
        "        print(\"Lỗi: Chưa tìm thấy model Spacy. Hãy chạy lại Bước 1 để tải en_core_web_sm/fr_core_news_sm.\")\n",
        "        return None, None\n",
        "def build_vocab(filepath, tokenizer):\n",
        "    def yield_tokens(path):\n",
        "        with io.open(path, encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    yield tokenizer(line.strip())\n",
        "    print(f\"Đang xây dựng vocab từ {filepath}...\")\n",
        "\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        yield_tokens(filepath),\n",
        "        min_freq=2,\n",
        "        max_tokens=10000,\n",
        "        specials=SPECIAL_SYMBOLS\n",
        "    )\n",
        "\n",
        "    vocab.set_default_index(UNK_IDX)\n",
        "    return vocab\n",
        "\n",
        "# 3. THỰC THI (MAIN)\n",
        "tokenizer_en, tokenizer_fr = get_tokenizers()\n",
        "if tokenizer_en and tokenizer_fr:\n",
        "    vocab_en = build_vocab('data/train.en', tokenizer_en)\n",
        "    vocab_fr = build_vocab('data/train.fr', tokenizer_fr)\n",
        "    # -----\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\" BÁO CÁO KẾT QUẢ\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"1. Kích thước từ điển EN: {len(vocab_en)} từ (Yêu cầu: <= 10004)\")\n",
        "    print(f\"2. Kích thước từ điển FR: {len(vocab_fr)} từ (Yêu cầu: <= 10004)\")\n",
        "    print(f\"3. Kiểm tra index token: <unk>={vocab_en['<unk>']}, <pad>={vocab_en['<pad>']}\")\n",
        "\n",
        "    # Kiểm tra xử lý từ lạ (OOV)\n",
        "    test_oov = vocab_en['từ_này_chắc_chắn_không_có']\n",
        "    if test_oov == UNK_IDX:\n",
        "        print(\"4. Xử lý từ lạ (OOV):  Thành công (Trả về index 0)\")\n",
        "    else:\n",
        "        print(f\"4. Xử lý từ lạ (OOV): Thất bại (Trả về {test_oov})\")\n",
        "    print(\"=\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2YzQaXJjaB1",
        "outputId": "0b519ee4-8391-4832-f805-7b1cb91a2398"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Đã tải thành công Tokenizer (Spacy).\n",
            "Đang xây dựng vocab từ data/train.en...\n",
            "Đang xây dựng vocab từ data/train.fr...\n",
            "\n",
            "========================================\n",
            " BÁO CÁO KẾT QUẢ\n",
            "========================================\n",
            "1. Kích thước từ điển EN: 6191 từ (Yêu cầu: <= 10004)\n",
            "2. Kích thước từ điển FR: 6555 từ (Yêu cầu: <= 10004)\n",
            "3. Kiểm tra index token: <unk>=0, <pad>=1\n",
            "4. Xử lý từ lạ (OOV):  Thành công (Trả về index 0)\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def text_transform(text, tokenizer, vocab):\n",
        "    tokens = tokenizer(text)\n",
        "    token_ids = [vocab[token] for token in tokens]\n",
        "    return torch.tensor([SOS_IDX] + token_ids + [EOS_IDX], dtype=torch.long)\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\" KIỂM TRA TEXT PIPELINE\")\n",
        "print(\"=\"*40)\n",
        "sample_sentence = \"Two young, White males are outside.\"\n",
        "print(f\"1. Câu gốc: {sample_sentence}\")\n",
        "\n",
        "# Chạy qua hàm transform\n",
        "sample_tensor = text_transform(sample_sentence, tokenizer_en, vocab_en)\n",
        "\n",
        "print(f\"2. Kết quả Tensor: {sample_tensor}\")\n",
        "print(f\"3. Shape: {sample_tensor.shape}\")\n",
        "print(f\"4. Kiểu dữ liệu: {sample_tensor.dtype}\")\n",
        "\n",
        "# Kiểm tra logic <sos> và <eos>\n",
        "if sample_tensor[0] == SOS_IDX and sample_tensor[-1] == EOS_IDX:\n",
        "    print(\"Logic <sos>/<eos>: Chính xác (Đầu là 2, Cuối là 3)\")\n",
        "else:\n",
        "    print(f\"Logic <sos>/<eos>:SAI (Đầu: {sample_tensor[0]}, Cuối: {sample_tensor[-1]})\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIH4Wa1SjfHn",
        "outputId": "c2b1246d-cd01-4754-8f9e-de1009b5593c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            " KIỂM TRA TEXT PIPELINE\n",
            "========================================\n",
            "1. Câu gốc: Two young, White males are outside.\n",
            "2. Kết quả Tensor: tensor([   2,   19,   25,   15, 1169,  808,   17,   57,    5,    3])\n",
            "3. Shape: torch.Size([10])\n",
            "4. Kiểu dữ liệu: torch.int64\n",
            "Logic <sos>/<eos>: Chính xác (Đầu là 2, Cuối là 3)\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. CLASS DATASET\n",
        "# ==============================================================================\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_list, trg_list):\n",
        "        self.src_list = src_list\n",
        "        self.trg_list = trg_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        return self.src_list[idx], self.trg_list[idx]\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. HÀM COLLATE_FN\n",
        "# ==============================================================================\n",
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = [], []\n",
        "\n",
        "    # Chuyển đổi Text -> Tensor\n",
        "    for src_sample, trg_sample in batch:\n",
        "        src_batch.append(text_transform(src_sample, tokenizer_en, vocab_en))\n",
        "        trg_batch.append(text_transform(trg_sample, tokenizer_fr, vocab_fr))\n",
        "\n",
        "    # Padding (Đồng bộ độ dài)\n",
        "    src_padded = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    trg_padded = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
        "\n",
        "    # Tính độ dài thực tế của từng câu nguồn\n",
        "    src_lens = torch.tensor([len(x) for x in src_batch])\n",
        "\n",
        "    # Sort giảm dần\n",
        "    sorted_lens, sorted_indices = torch.sort(src_lens, descending=True)\n",
        "\n",
        "    # Sắp xếp lại Tensor theo thứ tự index đã sort\n",
        "    src_padded = src_padded[:, sorted_indices]\n",
        "    trg_padded = trg_padded[:, sorted_indices]\n",
        "\n",
        "    return src_padded, trg_padded, sorted_lens\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. HÀM GET_DATA_LOADER\n",
        "# ==============================================================================\n",
        "def get_data_loader(dataset, batch_size, collate_fn, shuffle=False):\n",
        "    return DataLoader(dataset,\n",
        "                      batch_size=batch_size,\n",
        "                      shuffle=shuffle,\n",
        "                      collate_fn=collate_fn)\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. THỰC THI & TẠO LOADER\n",
        "# ==============================================================================\n",
        "BATCH_SIZE = 64\n",
        "train_dataset = TranslationDataset(train_en, train_fr)\n",
        "valid_dataset = TranslationDataset(val_en, val_fr)\n",
        "test_dataset  = TranslationDataset(test_en, test_fr)\n",
        "train_loader = get_data_loader(train_dataset, BATCH_SIZE, collate_fn, shuffle=True)\n",
        "valid_loader = get_data_loader(valid_dataset, BATCH_SIZE, collate_fn, shuffle=False)\n",
        "test_loader  = get_data_loader(test_dataset,  BATCH_SIZE, collate_fn, shuffle=False)\n",
        "# ==============================================================================\n",
        "# 5. KIỂM TRA LOGIC MỚI\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\" KIỂM TRA LOGIC MỚI\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Lấy 1 batch bất kỳ\n",
        "try:\n",
        "    src, trg, src_len = next(iter(train_loader))\n",
        "\n",
        "    print(f\"1. Shape Source: {src.shape}\")\n",
        "    print(f\"2. Shape Target: {trg.shape}\")\n",
        "    print(f\"3. Shape Lengths: {src_len.shape}\")\n",
        "\n",
        "    # Kiểm tra giá trị Length\n",
        "    print(f\"   - Length câu đầu tiên (Sau khi sort): {src_len[0]}\")\n",
        "    print(f\"   - Length câu cuối cùng (Sau khi sort): {src_len[-1]}\")\n",
        "\n",
        "    # Kiểm tra Sorting\n",
        "    if src_len[0] >= src_len[-1]:\n",
        "        print(\"KẾT QUẢ: Batch đã sort + Có trả về Lengths.\")\n",
        "        print(\"   -> Sẵn sàng cho Encoder (pack_padded_sequence).\")\n",
        "    else:\n",
        "        print(\" LỖI: Sort chưa đúng.\")\n",
        "\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Số batch trong train_loader: {len(train_loader)}\")\n",
        "    print(f\"Số batch trong valid_loader: {len(valid_loader)}\")\n",
        "    print(f\"Số batch trong test_loader: {len(test_loader)}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "except ValueError as e:\n",
        "    print(\" LỖI CẤU TRÚC: DataLoader không trả về đủ 3 giá trị!\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzRNeMyVjrEc",
        "outputId": "eb84c721-f65d-4d4c-f936-57cd614f5b51"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            " KIỂM TRA LOGIC MỚI\n",
            "========================================\n",
            "1. Shape Source: torch.Size([34, 64])\n",
            "2. Shape Target: torch.Size([34, 64])\n",
            "3. Shape Lengths: torch.Size([64])\n",
            "   - Length câu đầu tiên (Sau khi sort): 34\n",
            "   - Length câu cuối cùng (Sau khi sort): 9\n",
            "KẾT QUẢ: Batch đã sort + Có trả về Lengths.\n",
            "   -> Sẵn sàng cho Encoder (pack_padded_sequence).\n",
            "========================================\n",
            "Số batch trong train_loader: 454\n",
            "Số batch trong valid_loader: 16\n",
            "Số batch trong test_loader: 16\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHẦN 2: XÂY DỰNG MÔ HÌNH ENCODER-DECODER LSTM\n",
        "\n",
        "\n",
        "- Encoder: `(ht, ct) = LSTM(embed(xt), (ht-1, ct-1))`\n",
        "- Decoder: `(ht, ct) = LSTM(embed(yt-1), (h't-1, c't-1))` và `p(yt) = softmax(Linear(ht))`\n",
        "- Context vector cố định từ Encoder (không bắt buộc attention)\n",
        "\n",
        "**Tham số khuyến nghị:**\n",
        "- Hidden size: 512\n",
        "- Embedding dim: 256–512\n",
        "- Số layer LSTM: 2\n",
        "- Dropout: 0.3–0.5"
      ],
      "metadata": {
        "id": "wcQacjzMley_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. ENCODER\n",
        "# ==============================================================================\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_len):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        packed_embedded = pack_padded_sequence(embedded, src_len.cpu(), enforce_sorted=True)\n",
        "        packed_outputs, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. DECODER\n",
        "# ==============================================================================\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. SEQ2SEQ\n",
        "# ==============================================================================\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must match!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Number of layers of encoder and decoder must match!\"\n",
        "\n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        hidden, cell = self.encoder(src, src_len)\n",
        "        input = trg[0,:]\n",
        "\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "print(\"Đã xây dựng xong kiến trúc Model (Encoder - Decoder - Seq2Seq).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnwRGUmNnWMp",
        "outputId": "0b87e957-5f5d-43cf-e876-b7061b337b1b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã xây dựng xong kiến trúc Model (Encoder - Decoder - Seq2Seq).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Cấu hình Hyperparameters\n",
        "INPUT_DIM = len(vocab_en)\n",
        "OUTPUT_DIM = len(vocab_fr)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# Thiết bị\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 2. Khởi tạo Model\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "model.apply(init_weights)\n",
        "\n",
        "print(f\" Đã khởi tạo Model trên: {device}\")\n",
        "print(f\" Tổng số tham số: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "# 3. TEST KẾT NỐI VỚI DATALOADER (QUAN TRỌNG)\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\" KIỂM TRA KẾT NỐI DATA -> MODEL\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "try:\n",
        "    batch = next(iter(train_loader))\n",
        "    src, trg, src_len = batch\n",
        "    src = src.to(device)\n",
        "    trg = trg.to(device)\n",
        "\n",
        "    print(f\"1. Input Shape (Src): {src.shape}\")\n",
        "    print(f\"2. Input Lengths (Len): {src_len.shape}\")\n",
        "    print(f\"3. Target Shape (Trg): {trg.shape}\")\n",
        "    output = model(src, src_len, trg)\n",
        "    print(f\"4. Output Shape: {output.shape}\")\n",
        "\n",
        "    # Kiểm tra kích thước\n",
        "    if output.shape[0] == trg.shape[0] and output.shape[1] == trg.shape[1] and output.shape[2] == OUTPUT_DIM:\n",
        "        print(\"\\n THÀNH CÔNG\")\n",
        "        print(\"    Sẵn sàng cho quá trình Huấn luyện .\")\n",
        "    else:\n",
        "        print(\"\\n CẢNH BÁO: Kích thước đầu ra không khớp!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n LỖI KHI CHẠY THỬ: {e}\")\n",
        "    print(\"Gợi ý: Kiểm tra lại xem collate_fn ở Phần 1 có trả về đúng 3 giá trị không?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze_ZolHEnagI",
        "outputId": "73826325-e2df-43a3-d056-e6655e563720"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Đã khởi tạo Model trên: cpu\n",
            " Tổng số tham số: 13,982,107\n",
            "\n",
            "========================================\n",
            " KIỂM TRA KẾT NỐI DATA -> MODEL\n",
            "========================================\n",
            "1. Input Shape (Src): torch.Size([30, 64])\n",
            "2. Input Lengths (Len): torch.Size([64])\n",
            "3. Target Shape (Trg): torch.Size([33, 64])\n",
            "4. Output Shape: torch.Size([33, 64, 6555])\n",
            "\n",
            " THÀNH CÔNG\n",
            "    Sẵn sàng cho quá trình Huấn luyện .\n",
            "========================================\n"
          ]
        }
      ]
    }
  ]
}